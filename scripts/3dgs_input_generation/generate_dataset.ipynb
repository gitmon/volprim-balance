{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "jit_find_library(): Unable to load \"/usr/lib/llvm-15/lib/libLLVM.so\": /home/jonathan/miniconda3/envs/volprim/lib/python3.11/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /usr/lib/llvm-15/lib/libLLVM.so)!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/jonathan/Documents/mi3-gs/build/python')\n",
    "\n",
    "import drjit as dr\n",
    "from drjit.auto.ad import Float, UInt\n",
    "import mitsuba as mi\n",
    "mi.set_variant('cuda_ad_rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate scene renders\n",
    "Generates synthetic renders and camera poses to be used as input for a NeRF/GS surface reconstruction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from data_generation import CameraParameters, DataGenerator, make_hemispherical_cameras, make_spherical_cameras, concatenate_cameras\n",
    "import numpy as np\n",
    "\n",
    "xs = np.linspace(-3, 3, 5)\n",
    "zs = np.linspace(-4.5, 4.5, 5)\n",
    "xx, zz = np.meshgrid(xs, zs)\n",
    "centers = np.c_[xx.ravel(), zz.ravel()]\n",
    "\n",
    "scene = mi.load_file(\"../../scenes/mitsuba/classroom/scene.xml\")\n",
    "camera_params = CameraParameters(512, 512, fov=90, spp=64)\n",
    "camera_poses = concatenate_cameras([\n",
    "    make_spherical_cameras(center = np.array([x, 1.4, z]), radius = 0.2, outward = True, density = 0) for \\\n",
    "        x, z in zip(xx.ravel(), zz.ravel())])\n",
    "\n",
    "datagen = DataGenerator(scene, \"classroom_spp=64_dn\", camera_params, camera_poses, use_denoiser=True)\n",
    "# datagen.visualize()\n",
    "# datagen.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting render job for training data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:11<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data render complete.\n",
      "Starting render job for test data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:03<00:00, 25.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data render complete.\n"
     ]
    }
   ],
   "source": [
    "scene = mi.load_dict(mi.cornell_box())\n",
    "camera_params = CameraParameters(512, 512, 64, 90)\n",
    "camera_poses = make_spherical_cameras(center = np.array([0.0, 0.25, 0.75]), radius = 0.5, outward = False, density = 2)\n",
    "\n",
    "datagen = DataGenerator(scene, \"cbox\", camera_params, camera_poses, use_denoiser=False)\n",
    "# datagen.visualize()\n",
    "datagen.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting render job for training data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:29<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data render complete.\n",
      "Starting render job for test data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:07<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data render complete.\n"
     ]
    }
   ],
   "source": [
    "scene = mi.load_file(\"../../scenes/mitsuba/lego/scene.xml\")\n",
    "camera_params = CameraParameters(512, 512, 64, 45)\n",
    "camera_poses = make_hemispherical_cameras(center = np.array([0.5, 0.25, 0.5]), radius = 1.0, outward = False, tophalf = True, density = 2)\n",
    "\n",
    "datagen = DataGenerator(scene, \"lego\", camera_params, camera_poses, use_denoiser=False)\n",
    "# datagen.visualize()\n",
    "datagen.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3DGS visualization\n",
    "Overlay the trained 3DGS splats on top of the original Mitsuba scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "\n",
    "scene_fp = \"../../scenes/mitsuba/classroom/scene.xml\"\n",
    "scene = mi.load_file(scene_fp)\n",
    "data_fp = \"/home/jonathan/Documents/gaussian-splatting/output/mitsuba-classroom-64spp/point_cloud/iteration_30000/point_cloud.ply\"\n",
    "\n",
    "# scene = mi.load_dict(mi.cornell_box())\n",
    "# data_fp = \"/home/jonathan/Documents/gaussian-splatting/output/mitsuba-cbox/point_cloud/iteration_30000/point_cloud.ply\"\n",
    "\n",
    "with open(data_fp, 'rb') as f:\n",
    "    plydata = PlyData.read(f)['vertex']\n",
    "    points = np.c_[plydata['x'], plydata['y'], plydata['z']]\n",
    "    colors = np.c_[plydata['f_dc_0'], plydata['f_dc_1'], plydata['f_dc_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyscope as ps\n",
    "\n",
    "ps.init()\n",
    "ps_points = ps.register_point_cloud(\"GS points\", points)\n",
    "ps_points.add_color_quantity(\"Colors\", colors, enabled=True)\n",
    "\n",
    "for shape_id, shape in enumerate(scene.shapes()):\n",
    "    if not(shape.is_mesh()): continue\n",
    "\n",
    "    V = dr.unravel(mi.Point3f, shape.vertex_positions_buffer())\n",
    "    F = dr.unravel(mi.Point3u, shape.faces_buffer())\n",
    "    V, F = V.numpy().T, F.numpy().T\n",
    "    ps.register_surface_mesh(f\"mesh_{shape_id}\", V, F, edge_width=1.0)\n",
    "\n",
    "ps.show()\n",
    "\n",
    "ps.remove_point_cloud(\"GS points\")\n",
    "for shape_id, shape in enumerate(scene.shapes()):\n",
    "    try:\n",
    "        ps.remove_surface_mesh(f\"mesh_{shape_id}\")\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volprim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
